
Алгоритм розпізнавання об'єктів скл з 2 частин:

1) визначення координатів boundering box об'єкта:
	вектор: лівий нижній та правий верхній кут
	зображення - вхід
	(x1, y1, x2, y2) - вихід
	Intersection Over Union - перетин ділиться на об'єднання 2х bbox

2) визначення того який саме це об'єкт
	класифікація, кк виходів = кк класів об'єктів
	на вхід йде зображення з boundering box,
	координати котрого знайдені попередньо

----------------------------------------------------------------------------------------

Yolo:
	Початкові conv-шари мережі вибирають ознаки зображення,
	Кінцеві dense-шари передбачають за ними вихідні "ймовірності" та координати 

	Вхід не зображення ділиться на сітку розміром SxS клітинок
для кожного об'єкта на зображенні 1 клітинка здатна розпізнати його
це клітинка де розміщений центр об'єкта
	
	Кожна клітинка передбачає [B] boundering boxes та [C] ймовірностей класу(class probs)
bbox передбачення скл із 5 частин: (x, y, w, h, confidence), де:
	(x,y) - центр bbox, нормалізовані відносно w,h клітинки (0,1)
якщо центр bbox не впадає в клітинку, то вона відповідає за передбачення об'єкту
(w,h) - довжина та ширина bbox, нормалізовані по w,h зображення (0,1)
confidence - рівень довіри що в цій клітинці дійсноє об'єкт
confidence = probability(obj) * iou(pred,label)
probability(obj) - один з виходів мережі для кожного bbox, який потім множиться на iou 
якщо в цій клітинці нема об'єктів - conf=0, якщо є,то максимум буде=iou
	
	Кожна клітинка робить [B] передбачень (x,y,w,h,confidence)
відповідно SxSxB*5. Та [C] передбачень, C = кк класів
в 1 клітинці 1 сет передбачень класу, тому SxSxB*5+C

	ф-я активації всюди:
leaky relu

	ф-я помилки:
1)
	L1  *  sum[S^2]sum[B] Kij * ((x-x_pr)^2 + (y-y_pr)^2), де:
	K = 1, для bbox певної клітинки, iou(confidence) якого найбільше, якщо об'єкт є в клітинці(його центр)
	K = 0, інший випадок
	L1 = 5 - збільшення помилки для координат, та розміру
	Тобто помилка вираховується як сума різниці квадратів помилок для x, y координатів центра об'єкта
	
2)
	L1 *  sum[S^2]sum[B] Kij * (( w^(1/2) - w_pr^(1/2) )^2 + ( h^(1/2) - h_pr^(1/2) )^2), де:
	L1 - з 1)
	помилка має відображати менші відхилення у великих bbox менше ніж в малих,
	тому береться корінь

3)
	sum[S^2]sum[B] Kij * (с-iou)^2 + !L2 * sum[S^2]sum[B] !K * (с-iou)^2, де:
	L2 = 0.5 - зменшення помилки для довіри
	!k може застосовуватись тому, що покращення відбуваються тільки для bbox з max confidence
	значить помилка не для кожої ітерації, тому помилка збільшується прамопропорційно з кк bbox в клітині
	але з меншим (L2) коефіцієнтом ніж основна

4)
	sum[S^2] Ki * sum[classes] (p(c) - p_pr(c))^2, де:
	таким чином якщо(центра) об'єкта в клітинці нема,
	помилка класу вираховуватись не буде

	Вихід:
виходів має бути SxSxB*5+C
SxS передбачень -> [B] bboxs -> (x,y,w,h,confidence) + [C] класів 

є 2 типи K:
Ki(obj) = 1 - коли у клітині[i] є об'єкт(центр obj у ній -> хоч 1 її bbox правдиво має бути responsible за нього)
K1(obj) = 0 - у іншому випадку
Kij(obj) = 1 - коли bbox[j] клітини[i] responsible за obj
Ki(obj) = 0 - у іншому випадку
bbox responsible за obj коли в bbox max(iou) в цій клітині для даного obj
1 клітина може розпізнавати тільки 1 об'єкт - якщо його центер в ній

якщо об'єкт великий то можна розділити на частини
і розпізнавати їх, тільки прийдеться розмітити датасет

ВИХІД ПО КЛІТИНАХ СІТКИ, ТОМУ ТРЕБА РОЗМІТИТИ ДЛЯ КОЖНОЇ КЛІТИНИ (x,y,w,h,conf) - (дані для conf)

під час тесування:
 prob(class|obj)*prob(obj)*iou = prob(class) * iou
 що дає залежні від класу очки довіри для кожного bbox
 це показує повну ймовірність: що в bbox знаходиться об'єкт,
 та об'єкт саме того класу (якого prob(class|obj) )